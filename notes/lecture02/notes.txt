------------------------
LECTURE 2: Tuesday 10/06
------------------------

OS services are offered as abstractions in basic categories:
- CPU/memory abstractions   
    - CPU: processes, threads, VMs - actively execute code 
    - memory: virtual address sapces, shared segments 
- Persistent storage abstractions 
    - Files and file systems 
- Other I/O abstractions 
    - Virtual terminal sections, windows 
    - Sockets, pipes, VPNs, signals, (as interrupts)
- Cooperating parallel processes   
    - locks, condition variables 
    - distributed transactions, leases 
- Security 
- UI

(not directly visible to users)
- Enclosure management 
    - Hot-plug, power, fans, fault handling 
- Software updates and configuration registry 
- Dynamic resource allocation and scheduling 
    - CPU, memory, bus resources, disk, network 
- Networks, protocols, domain services 
    - USB, BlueTooth 
    - TCP/IP, DHCP, LDAP, SNMP
    - iSCISI, CIFS, NFS 

How to tell the OS to deliver these services?
- Several options that each work at different layers of the sw stack
    (1) Applications call subroutines 
    (2) Applications make system calls 
    (3) Applications could send messages to software that performs the services 

OS Layering - layers of sw and hw
- High level abstract services offered at high level software layers 
- Lower level abstract services offered deeper in the OS 
- Ultimately, everything mapped down to relatively simple hardware 

[SEE IMAGE: layer.png]  
    Application binary interface: everything on top must meet this interface 
    Middleware: useful high level abstractions 

(1) Service delivery via SUBROUTINE CALLS
- push parameters, jump to subroutine, return values in registers on the stack 
- typically at high layers 
- Advantages
    - very fast (nano-seconds)
    - run-time implementation binding possible 
- Disadvantages
    - all services are implemented in same address space 
    - limited ability to combine different languages 
    - can't usually use privilged instructions 

Service delivery via libraries 
- one subroutine service delivery approach 
- programmers dont need to write all code for programs - standard utility functions are found in libraries 
- a library is a collection of object modules: 
    - single file that contains many files (like zip or jar)
    - these modules can be used directly without recompilation 
- Most systems come with many standard libraries
    - system services, encryption, statistics, etc.
    - additional libraries may come with add-on products 
- Programmers can build their own libraries 
    - functions commonly needed by parts of a product 
- [SEE IMAGE: layer.png] general libraries are compiled binaries 
- Advantages
    - reusable code -> easier programming
    - well written and maintained 
    - encapsulates complexity -> better building spots 
- Multiple bind-time options 
    - static - include in load module at link time 
    - shared - map into address space at exec time (no need to have copies of same library)
        - at link time, say: it's a shared program, we'll access it later 
    - dynamic - choose and load at run time 
- It's only code, it has no special privileges 

*   compile -> link (here have machine language) -> load -> run 
    C -> assembly -> machine language (what the CPU can actually run)

Sharing libraries 
- Static library modules are added to a program's load module 
    - Each load module has its own copy of each library -> dramatically increases size of each process 
    - Prgram must be re-linked to incorporate new library - existing load modules don't benefit form bug fixes
- Instead, make each library a sharable code segment 
    - One in-memory copy, shared by all processes 
    - Keep the library separate from the load modules 
    - OS loads library along with the program 
- Advantages of shared libraries 
    - Reduced memory consumption 
    - Faster program startups because no need to load again 
    - Simplified udpates
- Limitations 
    - Not all modules will work in a shared library - cannot define/include global data storage 
    - Added into program memory whether they are actually needed or not 
    - Called routines must be known at compile time: 
        - Only the fetching of the code is delayed 'til run-time
        – Symbols known at compile time, bound at link time
    - Dynamically Loadable Libraries are more general
        – They eliminate all of these limitations ... at a price

[SEE IMAGE: libraries.png]


(2) Service delivery via SYSTEM CALLS 
- Force an entry into OS 
    - Parameters/returns similar to subroutine 
    - Implementation is in shared/trusted kernel 
- Advantages - things you can do that you can't do with library calls 
    - Able to allocate/use new/privileged resources 
    - Able to share/communicate wiht other processes 
- Disadvantages 
    - All implemented on the local node - can't do system call on another machine 
    - 100x to 1000x slower than subroutine calls 
- Usually do not write your own system call, usually call library functions that perform system call

*   Methods are object-oriented
    Subroutine are similar to functions. A subroutine call calls a piece of code, providing prarameters -> push frame onto stack 

Providing services via Kernel 
- Primary functions that require privilege 
    - Privileged instructions (e.g. interrupts, I/O)
    - Allocation of physical resources (e.g. memory)
    - Ensure process privacy and containment 
    - Ensure integrity of critical resources 
- Some operations may be out-sourced by kernel to another process that can do something without assistance of the kernel 
    - System daemons, server processes 
- Some plug-ins may be less trusted 
    - Device drivers, file systems, network protocols 

[SEE IMAGE: layer.png] - OS kernel (red)

System services outside the kernel 
- Not all trusted code must be in the kernel 
    - It may not need to access kernel data structures 
    - It may not need to execute privileged instructions 
- Some are actually somewhat privileged processes 
    - Login can create/set user credentials 
    - Some can directly execute I/O operations 
- Some are merely trusted 
    - sendmail is trusted to properly label messages 
    - NFS server is trusted to honor access control data 

[SEE IMAGE: layer.png] - OS services (orange) 

Service delivery via MESSAGES
- Exchange messages with a server which is a process (via syscalls)
    - Parameters in request, returns in response 
- Advantages 
    - Server can be anywhere on earth (or local)
    - Service can be highly scalable and available 
    - Service can be implemented in user-mode code 
- Disadvantages
    - 1000x to 100,000x slower than subroutine 
    - Limited ability to operate on process resources 

Service delivery via MIDDLEWARE 
- Software that is a key part of the app or service platform, but not part of the OS 
    - Databse, pub/sub messaging system 
    - Apache, Nginx 
    - Hadoop, Zookeeper, Beowulf, OpenStack 
    - Cassandra, RAMCloud, Ceph, Gluster 
- Kernel code is very expensive and dangerous because if kernel crashes everything crashes 
- Middleware is in user mode 
    - User mode code is easier to build, test and debug 
    - User mode code is much more portable 
    - User mode code can crash and be restarted 
- Middleware is given specific privileges that the kernel will allow to make use of these functions 

* Usually, kernel is the highest level of privilege 
* Kernel runs privileged instructions and is allowed to run any privileged instruction 
* Very hard to debug kernel crashes 

OS Interfaces 
- Nobody buys a computer to run the OS 
- The OS is meant to support other programs via its abstract services like file system 
- Usually intended to be very general and able to support many different programs 
- Interfaces are needed b/w teh OS and other programs to offer general services 

Interfaces: API = application program interfaces 
- Help you write programs for your OS
- Interface at the source code level 
- Source level interface that specifies: 
    - Include files, data types, constatns 
    - Macros, routines, paramters 
- Basis for software portability 
    - Recompile program for the desired architecture 
    - Linkage edit with OS-specific libraries 
    - Resulting binary runs on anything with that architecture and OS
- An API compliant program will compile and run on any compliant system 
    - APIs are primarily for programmers 

Interfaces: ABIs = application bianry interfaces
- ABIs help you install binaries on your OS 
- Binary interface specifying
    - Dynamically loadable libraries (DLLs)
    - Data formats, calling sequences, linking conventions 
- Binds of an API (alr specific to OS) to hw architecture -> ABI also specific to OS 
- Bases for binary compatbility 
    - One binary serves all customers for that hardware e.g. all x86 Linux/BSD/MacOS/Solaris/...
- An ABI compliant progarm will run (unmodified) on any compliant system 
- ABIs are primarily for users: you know that when you buy progarm for your OS and your ISA, you know the program will run. You don't have to compile and re-link and change system calls because it's different OS 

Libraries and interfaces 
- Normal libraries (shared and otherwise) are accessed through an API 
    - Source-level definitions of how to access the library 
    - Readily portable between different machines 
- Dynamically loadable libraries also called through an API 
    - But the dynamic loading mechanism is ABI-specific 
    - Issues of word length, stack format, linkages, etc. 

Interfaces and Interoperatability 
- Strong, stable interfaces are key to allowing programs to operate together 
- Key to OS evolution 
- Don't want OS upgrade to break your existing programs
- Which means the interface b/w OS and programs better not change
- Can't change ABI because API compiles into ABI 

Interoperatability requires stability 
- No program is an island 
    - Programs use system calls 
    - Programs call library routines 
    - Programs operate on external files 
    - Programs exchange messages with other software 
    - If interfaces change, program fails 
- API requirements are frozen at compile time
    - Excution platform must support those interfaces
    – All partners/services must support those protocols
    – All future upgrades must support older interfaces

Interoperatability requires compliance 
- Complete interoperability testing is impossible
    – Cannot test all applications on all platforms
    – Cannot test interoperability of all implementations
    – New apps and platforms are added continuously
- Instead, we focus on the interfaces 
    - Interfaces are completely and rigorously specified
    - Standard bodies manage the interface definitions 
    - Compliance suites validate the implementations 
- And hope that sampled testing will suffice 

Side effects 
- A side effect occurs when an action on one object has non-obvious consequences 
    - Effects not specified by interfaces 
    - Perhaps even to other objects 
- Often due to shared state between seemingly independent modules and functions 
- Side effects lead to unexpected behaviors 
- Resulting bugs can be hard to find / nondeterministic -> bad 

Abstractions 
- Many things an OS handles are complex, often due to varieties of hw, sw, configurations
- Life is easy for app programmers and users if they work with a simple abstraction
- OS creates, manages, and exports such abstractions

Simplifying abstractions 
- HW is fast but complex and limited 
    - Using it correctly is complicated
    - May not support needed functionality 
    - Not solution but a building block 
- Abstractions  
    - Encapsulate implementation details: error handling, optimization -> elimintate behaviro irrelevant to user 
    - Provide convenient or powerful behavior: operations better suited to user needs 

Critical OS abstractions:

(1) Memory abstractions 
- Need to store variables, allocated memory, files, database records, messages to send/receive 
- Similar properties: you read and write them but there are complications:
    - Persistent (hard drive, disk drive) vs transient (RAM) memory = will live beyond power turned off
    - Size of memory operations 
        - Size user/application wants to work with 
        - Size physical device actually works with 
    - Coherence and atomicity 
    - Latency - how long does it take to do the read/write (RAM is fast, hard drive slow, disk drive slower)
    - Same abstraction might be implemented with many different physical devices 
        - Possibly very different types
    - At the bottom, the OS doesn't have abstract devices with arbitrary propeties 
    - It has particular devices with unchangeable, often inconvenient properties 
    - The core OS abstraction problem: Create the abstract device with the desirable properties from the physical device that lacks them 
- For example, a typeical file that we can read or write any amount of data   
    - Coherence = write -> exect next read to reflect results of write 
    - Atomicity = expect entire read/write to occur 
    - If we do several reads/writes to file, we expect them to occur in some order, perhaps the order we asked but certainly in correct order relative to other operations before and after 
    - What is implementing file? 
        - Often a flash drive
            - Write-once (sort of) semantics: once you read it, you cannot overwrite but you can erase a whole ass block in an erase cycle to be able to re-write. Is slow. 
            - Atomicity of writing typically at word level - guarantee entire word is written
            - Blocks can only be erased so many times -> that block disappears 
        - So, the OS needs to smooth out these oddities 
    - What do these complexities lead to? 
        - Different structures for file system since you can't easily overwrite data words in place
        - Garbage collection on flash drive - needed to deal with blocks largely filled with inactive data while moving active data to somwhere else so we can erase original block 
        - Maintain a pool of empty blocks for writes 
        - Wear-leveling in use of blocks - now done with hardware associated with flash drive 
        - Something to provide desired atomicity of multi-word writes 

Abstracitons of Interpreters 
- Interpreter = something that performs commands 
- Basically the element of a computer (abstract or physical) that gets things done 
- At the physical level, we have a processor that is not easy to use 
- OS provides us higher level interpreter abstractions 

Basic Interpreter Components
- An instruction reference tells the interpreter which instruction to do next
- A repertoire = the set of things the interpreter can do
- An environment reference = the current state on which the next instruction should be performed
- Interrupts = Situations in which the instruction reference pointer is overridden

For example, a process a common high-level interpretor
- OS maintains program counter for process (instruction reference)
- Its source code specifies its repretroire 
- Its stack, heap, and register contents are its environment with OS maintaining pointers to all of them 
- No other interpreters should be able to mess up the process's instructions 

Implementing process abstraction in the OS 
- Easy if there's only one process, but there are almost always multiple processes 
- OS has limited physical memory (RAM) to hold information 
- Usually one set of registers, one per core 
    - If we have 200 processe seach with a set of registers, we can't run all of them on registers -> need to switch out data on registers when switching between processes 
- Process shares the CPU or core with other processes - must move processes on and off core, each process must start up on core in same way as it left the core last time 
    - Core is a serially reusable resource that requires clean transitions 

What does this lead to? 
- Schedulers to share the CPU among various processes 
- Memory management hardware and software 
    - To multiplex memory use among the processes 
    - Giving each the illusion of full exclusive use of memory 
- Access control mechanisms for other memory and abstractions 
    - So other processes can't fiddle with my files 

Abstractions of communcication 
- A communication link allows one interpreter to talk to another on the same or different machines
    - e.g. piping `ls` to `more` is a one directional communication channel 
- At the physical level, memory and cables 
- At more abstracts, networks and interprocess communication mechanisms 
- Some similarities to memory abstractions but also differences 

Why are comm links distinct from memory? 
- Highly variable performance 
- Often asynchronous -> issues with synchronizing the parties (don't know when receiver gets message)
- Receiver may only perform the operation because the send occurred (receiver does nothing if sender doesn't send)
    - Unlike a typical read or write that is guaranteed to happen if asked to 
- Additional complicaitons when working w a remote machine 

Implementing comm link abstraction in OS 
- Easy if both ends are on same machine, hard if they aren't 
- On same machine use memory transfer 
    - Copy message from sender's memory to receiver's
    - Or transfer control of memory containing the message from sender to receiver 
- Again, more complicated when remote 

What does that lead to? 
- Need to optimize costs of copying 
- Tricky memory management 
- Inclusion of complex network protocols in the OS itself 
- Worries about message loss, retransmission, etc. 
- New security concerns that OS might need to address 

Generalizingn abstractions 
- How can applications deal w/ many varied resources? 
- Make many different things appear the same 
    - Applications can all deal with a single class 
    - Often lowest common denomenator + subclasses 
- Requires a common/unifying model 
    - Portable document format (PDF) for printed output 
    - SCSI/SATA/SAS standard for disks, CDs, SSDs 
- Usually involves a federation framework 

Federation framework = a structure that allows many similar but somewhat different things to be treated uniformly 
- Doesn't want ppl working above this level have to worry about these differences 
- Does this by creating one interface that all users must meet 
- Then plugging in implementations for the particular things you have 
- e.g. making all hard disk drives accept the same commands even though you have 5 different models installed 

Are federation frameworks limiting? 
- Does common model have ot be the lowest common denomenator? 
- Not necessarily, because model can include "optional features" which if present are implemented in a standard way, but may not always be present and can be tested for 
- Many devices will have features that can't be exploited with common model -> arguments for and against value of such features 

Abstracitons + layering 
- It's common to create increasingly complex services by layering abstractions 
    - e.g. generic file system layers on a particular file system, which layers on abstract disk, which layers on a real disk 
- Layering allows good modularity 
    - Easy to build multiple services on a lower layer, e.g. multiple file systems on one disk 
    - Easy to use multiple underlying services to support a higher layer 
    - e.g. file system can have either a single disk or a RAID below it 